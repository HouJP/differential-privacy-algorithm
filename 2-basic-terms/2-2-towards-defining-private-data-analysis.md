---
layout:
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# 2.2 迈向隐私数据分析的定义

[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC\_BY--NC--ND\_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/) [![Status](https://img.shields.io/badge/Github-Ready-lightgrey.svg?logo=github)](https://github.com/HouJP/the-algorithmic-foundations-of-differential-privacy)

在数据分析的背景下，定义隐私的一种自然的方法是要求分析人员在完成数据分析后，对数据集中任何人的了解与之前相比没有增加。通过要求攻击者对个人的先验观点和后验观点（即访问数据库前后的看法）不应“差异太大”，或者通过要求对数据库的访问不应“过多”地改变攻击者对个人的看法，也可以很自然地形式化这个目标。然而，只要我们可以通过数据库学习到任何内容，这种隐私概念就是不切实际的。打个比方，假设攻击者有一个（错误的）先验观点是每个人都有两只左脚。通过访问统计数据库后发现，几乎每个人都有一只左脚和一只右脚。现在，攻击者对于任何特定的受访者是否有两只左脚的观点已经被彻底改变了。

通过前后对比或者约束“无信息泄漏”来定义隐私的吸引力在于它符合我们的直觉：如果没有泄漏个人的任何信息，那么这个人就不会因为数据分析而受到伤害。然而，“吸烟致癌”的例子表明这种直觉是错误的，其原因在于辅助信息（$$X$$先生吸烟）。

以上定义隐私的“无信息泄漏”方法与密码系统中的语义安全 (semantic security) 概念有着相似之处。粗略来讲，语义安全是指无法从密文中了解关于明文（未加密消息）的任何信息。也就是说，在阅读密文后所了解的任何有关明文的信息，都是在阅读密文之前就已知的。因此，即使存在辅助信息表明被加密的内容是“狗”或“猫”，密文无法让你更进一步分辨哪个才是被加密的内容。从形式上来说，我们可以通过比较窃听者猜测加密对象（是“狗”还是“猫”）的能力，以及所谓的**对抗模拟器** (adversary simulator) 猜测相同内容的能力来对此进行建模。其中，对抗模拟器知晓辅助信息，但是无法访问密文。如果在窃听者和模拟器都知晓所有辅助信息的情况下，针对不同的窃听者，对抗模拟器猜测出正确答案的可能性都与之基本相同，那么该系统就具备语义安全的性质。当然，要使系统真正可用，合法接收者必须能够正确解密消息，否则任何无法解密消息的系统都能轻易满足语义安全的性质，但毫无实用价值。

我们知道，在标准计算假设下，存在语义安全的加密系统，那么为什么我们不能构建语义安全的隐私数据库机制，在保证各行数据隐私的同时提供查询结果呢？

首先，这个类比并不完美：在语义安全的加密系统中，存在三个参与者：消息发送着（加密明文消息）、消息接收者（解密密文）和窃听者（因无法了解任何发送前未知的明文消息而感到沮丧）。相比之下，在隐私数据分析的场景下，只有两方参与：执行隐私机制的管理者（类似于消息发送者）和数据分析人员，后者接收针对查询的响应信息（类似于消息接收者），同时也在尝试获取个人的敏感信息（类似于窃听者）。由于数据分析人员既是合法接收者，也是试图窥探隐私的攻击者，因此将其与加密进行类比存在缺陷：拒绝向攻击者提供任何信息意味着拒绝向数据分析人员提供任何信息。

其次，与加密方案一样，我们需要确保隐私方案的可用性，这意味着它能够教给分析人员一些她之前不知道的信息。这种信息对于对抗模拟器是不可获取的，也就是说，模拟器无法“预测”分析人员学到了什么。因此，我们可以将数据库视为一种（不可预测的）弱随机位来源，从中提取高质量的随机性用作**随机填充** (random pad)。它可被用于一项加密技术：将机密信息添加到一个随机值（“随机填充”）中，以生成一个从信息理论角度隐藏机密信息的字符串。只有知道随机填充的人才能解密信息；任何对填充一无所知的人，无论其计算能力如何强大，都无法获知机密信息。由于数据分析人员可以访问数据库，所以他们可以学到随机填充，而没有数据库访问权限的对抗模拟器则无法获得有关填充的任何信息。因此，假设辅助信息是使用随机填充加密的机密信息，那么分析人员可以对其解密，但对抗模拟器则无法获知任何机密信息。这导致了攻击者/分析人员与对抗模拟器在获取机密信息的能力方面存在巨大差距，彻底破灭了和语义安全进行类比的可能性。

无论是在吸烟致癌的例子还是语义安全的类比中，阻碍我们实现目标的都是辅助信息。显然，为了使隐私保护具有意义，既是在存在“合理”辅助信息的情况下，它也应该依然有效。然而，如何区分合理的辅助信息本身也是一个难题。例如，使用政府数据库的分析人员可能同时也是一家大型搜索引擎公司的员工。对于此类人员可能掌握的辅助信息，我们应该如何做出“合理”的假设呢？
